[package]
name = "kokoro-openai-server"
version = "0.1.0"
edition = "2021"
authors = ["Kokoro OpenAI Server Contributors"]
description = "OpenAI-compatible TTS server for Kokoro model"
license = "MIT OR Apache-2.0"
repository = "https://github.com/yourusername/kokoro-openai-server"
keywords = ["tts", "openai", "kokoro", "api", "server"]
categories = ["multimedia::audio", "web-programming::http-server"]

[dependencies]
# Async runtime
axum = { version = "0.7", features = ["multipart"] }
tokio = { version = "1.35", features = ["full"] }
tower-http = { version = "0.5", features = ["cors", "trace", "compression-br"] }
tokio-stream = "0.1"
futures = "0.3"
async-stream = "0.3"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Validation
validator = { version = "0.16", features = ["derive"] }

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt"] }

# CLI
clap = { version = "4.4", features = ["derive", "env"] }

# Audio
hound = "3.5"

# ONNX Runtime
ort = { version = "2.0.0-rc.9", default-features = false, features = ["ndarray"] }

# HTTP client (for model downloads)
reqwest = { version = "0.11", features = ["blocking", "rustls-tls"], default-features = false }

# Utilities
uuid = { version = "1.6", features = ["v4"] }
regex = "1.10"
once_cell = "1.19"
ndarray = "0.15"
dirs = "5.0"

# Kokoro TTS inference (from GitHub)
kokoros = { git = "https://github.com/lucasjinreal/Kokoros", branch = "main" }
# Note: We're implementing our own OpenAI compatibility layer

[dev-dependencies]
tower = "0.4"
hyper = { version = "1.0", features = ["full"] }

[features]
default = ["coreml"]
cpu = []
coreml = ["ort/coreml"]
cuda = ["ort/cuda"]
directml = ["ort/directml"]

[profile.release]
opt-level = 3
lto = "thin"
codegen-units = 1
panic = "abort"

[profile.dev]
debug = true
opt-level = 0