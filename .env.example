# Environment Configuration
# Copy this file to .env and customize

# Server settings
HOST=0.0.0.0
PORT=8000

# Optional API key for authentication
# API_KEY=your-secret-key-here

# Model configuration
# MODEL_PATH=/path/to/kokoro.onnx

# Execution provider: auto, cpu, coreml (macOS), cuda (Linux), directml (Windows)
EXECUTION_PROVIDER=auto

# Parallel inference workers (1-8)
WORKERS=2

# Maximum input text length
MAX_INPUT_CHARS=4096

# Logging level
RUST_LOG=kokoro_openai_server=info,axum=info